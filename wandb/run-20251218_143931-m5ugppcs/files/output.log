  0%|                                                                                                                                            | 0/104061 [00:00<?, ?it/s]/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
                                                                                                                                                                            
{'loss': 1.9626, 'learning_rate': 6.406149903907751e-09, 'epoch': 0.0}
{'loss': 1.93, 'learning_rate': 1.2812299807815502e-08, 'epoch': 0.0}
{'loss': 1.804, 'learning_rate': 1.9218449711723257e-08, 'epoch': 0.0}
{'loss': 1.8601, 'learning_rate': 2.5624599615631005e-08, 'epoch': 0.0}
{'loss': 2.5088, 'learning_rate': 3.203074951953876e-08, 'epoch': 0.0}
{'loss': 2.2998, 'learning_rate': 3.8436899423446514e-08, 'epoch': 0.0}
{'loss': 2.9599, 'learning_rate': 4.4843049327354265e-08, 'epoch': 0.0}
{'loss': 2.4998, 'learning_rate': 5.124919923126201e-08, 'epoch': 0.0}
{'loss': 1.6927, 'learning_rate': 5.7655349135169774e-08, 'epoch': 0.0}
{'loss': 2.2663, 'learning_rate': 6.406149903907752e-08, 'epoch': 0.0}
{'loss': 2.6654, 'learning_rate': 7.046764894298526e-08, 'epoch': 0.0}
{'loss': 3.3728, 'learning_rate': 7.687379884689303e-08, 'epoch': 0.0}
{'loss': 2.1851, 'learning_rate': 8.327994875080077e-08, 'epoch': 0.0}
{'loss': 1.9271, 'learning_rate': 8.968609865470853e-08, 'epoch': 0.0}
{'loss': 2.422, 'learning_rate': 9.609224855861628e-08, 'epoch': 0.0}
{'loss': 2.6564, 'learning_rate': 1.0249839846252402e-07, 'epoch': 0.0}
{'loss': 2.5971, 'learning_rate': 1.0890454836643178e-07, 'epoch': 0.0}
{'loss': 1.8082, 'learning_rate': 1.1531069827033955e-07, 'epoch': 0.0}
{'loss': 3.22, 'learning_rate': 1.2171684817424729e-07, 'epoch': 0.0}
{'loss': 2.1362, 'learning_rate': 1.2812299807815505e-07, 'epoch': 0.0}
{'loss': 2.809, 'learning_rate': 1.345291479820628e-07, 'epoch': 0.0}
{'loss': 1.8562, 'learning_rate': 1.4093529788597053e-07, 'epoch': 0.0}
{'loss': 2.5995, 'learning_rate': 1.473414477898783e-07, 'epoch': 0.0}
{'loss': 2.0675, 'learning_rate': 1.5374759769378605e-07, 'epoch': 0.0}
{'loss': 1.924, 'learning_rate': 1.601537475976938e-07, 'epoch': 0.0}
{'loss': 2.3439, 'learning_rate': 1.6655989750160153e-07, 'epoch': 0.0}
{'loss': 1.5606, 'learning_rate': 1.7296604740550932e-07, 'epoch': 0.0}
{'loss': 2.1589, 'learning_rate': 1.7937219730941706e-07, 'epoch': 0.0}
{'loss': 2.074, 'learning_rate': 1.857783472133248e-07, 'epoch': 0.0}
{'loss': 1.9908, 'learning_rate': 1.9218449711723256e-07, 'epoch': 0.0}
{'loss': 1.5185, 'learning_rate': 1.985906470211403e-07, 'epoch': 0.0}
{'loss': 2.1715, 'learning_rate': 2.0499679692504804e-07, 'epoch': 0.0}
{'loss': 1.9622, 'learning_rate': 2.1140294682895583e-07, 'epoch': 0.0}
{'loss': 2.418, 'learning_rate': 2.1780909673286357e-07, 'epoch': 0.0}
{'loss': 3.4568, 'learning_rate': 2.242152466367713e-07, 'epoch': 0.0}
{'loss': 2.2974, 'learning_rate': 2.306213965406791e-07, 'epoch': 0.0}
{'loss': 2.0618, 'learning_rate': 2.3702754644458683e-07, 'epoch': 0.0}
{'loss': 1.7381, 'learning_rate': 2.4343369634849457e-07, 'epoch': 0.0}
{'loss': 3.7569, 'learning_rate': 2.4983984625240236e-07, 'epoch': 0.0}
{'loss': 2.9256, 'learning_rate': 2.562459961563101e-07, 'epoch': 0.0}
{'loss': 2.1957, 'learning_rate': 2.6265214606021784e-07, 'epoch': 0.0}
{'loss': 4.7506, 'learning_rate': 2.690582959641256e-07, 'epoch': 0.0}
{'loss': 2.208, 'learning_rate': 2.754644458680333e-07, 'epoch': 0.0}
{'loss': 2.239, 'learning_rate': 2.8187059577194105e-07, 'epoch': 0.0}
{'loss': 2.4536, 'learning_rate': 2.8827674567584884e-07, 'epoch': 0.0}
{'loss': 2.1756, 'learning_rate': 2.946828955797566e-07, 'epoch': 0.0}
{'loss': 3.293, 'learning_rate': 3.010890454836643e-07, 'epoch': 0.0}
{'loss': 2.0907, 'learning_rate': 3.074951953875721e-07, 'epoch': 0.0}
{'loss': 2.1887, 'learning_rate': 3.1390134529147985e-07, 'epoch': 0.0}
{'loss': 2.9169, 'learning_rate': 3.203074951953876e-07, 'epoch': 0.0}
{'loss': 3.9973, 'learning_rate': 3.267136450992953e-07, 'epoch': 0.0}
{'loss': 2.1646, 'learning_rate': 3.3311979500320306e-07, 'epoch': 0.0}
{'loss': 1.8789, 'learning_rate': 3.395259449071109e-07, 'epoch': 0.0}
{'loss': 1.8889, 'learning_rate': 3.4593209481101864e-07, 'epoch': 0.0}
{'loss': 2.0727, 'learning_rate': 3.523382447149264e-07, 'epoch': 0.0}
{'loss': 2.17, 'learning_rate': 3.587443946188341e-07, 'epoch': 0.0}
{'loss': 2.2123, 'learning_rate': 3.6515054452274186e-07, 'epoch': 0.0}
{'loss': 1.9956, 'learning_rate': 3.715566944266496e-07, 'epoch': 0.0}
{'loss': 2.2805, 'learning_rate': 3.779628443305574e-07, 'epoch': 0.0}
{'loss': 1.9166, 'learning_rate': 3.843689942344651e-07, 'epoch': 0.0}
{'loss': 2.0668, 'learning_rate': 3.9077514413837286e-07, 'epoch': 0.0}
{'loss': 1.9756, 'learning_rate': 3.971812940422806e-07, 'epoch': 0.0}
{'loss': 2.9581, 'learning_rate': 4.0358744394618834e-07, 'epoch': 0.0}
{'loss': 2.0693, 'learning_rate': 4.099935938500961e-07, 'epoch': 0.0}
{'loss': 2.2087, 'learning_rate': 4.163997437540039e-07, 'epoch': 0.0}
{'loss': 1.4768, 'learning_rate': 4.2280589365791166e-07, 'epoch': 0.0}
{'loss': 2.4404, 'learning_rate': 4.292120435618194e-07, 'epoch': 0.0}
{'loss': 1.883, 'learning_rate': 4.3561819346572713e-07, 'epoch': 0.0}
{'loss': 1.9479, 'learning_rate': 4.4202434336963487e-07, 'epoch': 0.0}
{'loss': 2.0976, 'learning_rate': 4.484304932735426e-07, 'epoch': 0.0}
{'loss': 2.1633, 'learning_rate': 4.548366431774504e-07, 'epoch': 0.0}
{'loss': 3.0953, 'learning_rate': 4.612427930813582e-07, 'epoch': 0.0}
{'loss': 2.1699, 'learning_rate': 4.6764894298526593e-07, 'epoch': 0.0}
{'loss': 1.9255, 'learning_rate': 4.7405509288917367e-07, 'epoch': 0.0}
{'loss': 2.0632, 'learning_rate': 4.804612427930814e-07, 'epoch': 0.0}
{'loss': 1.694, 'learning_rate': 4.868673926969891e-07, 'epoch': 0.0}
{'loss': 2.399, 'learning_rate': 4.932735426008969e-07, 'epoch': 0.0}
{'loss': 1.6879, 'learning_rate': 4.996796925048047e-07, 'epoch': 0.0}
{'loss': 1.8299, 'learning_rate': 5.060858424087125e-07, 'epoch': 0.0}
{'loss': 3.1032, 'learning_rate': 5.124919923126202e-07, 'epoch': 0.0}
{'loss': 2.1881, 'learning_rate': 5.188981422165279e-07, 'epoch': 0.0}
{'loss': 2.292, 'learning_rate': 5.253042921204357e-07, 'epoch': 0.0}
{'loss': 2.2754, 'learning_rate': 5.317104420243434e-07, 'epoch': 0.0}
{'loss': 2.2808, 'learning_rate': 5.381165919282512e-07, 'epoch': 0.0}
{'loss': 3.0984, 'learning_rate': 5.445227418321589e-07, 'epoch': 0.0}
{'loss': 2.3918, 'learning_rate': 5.509288917360666e-07, 'epoch': 0.0}
{'loss': 2.328, 'learning_rate': 5.573350416399744e-07, 'epoch': 0.0}
{'loss': 3.0223, 'learning_rate': 5.637411915438821e-07, 'epoch': 0.0}
{'loss': 2.1694, 'learning_rate': 5.701473414477899e-07, 'epoch': 0.0}
{'loss': 2.9684, 'learning_rate': 5.765534913516977e-07, 'epoch': 0.0}
{'loss': 1.7865, 'learning_rate': 5.829596412556054e-07, 'epoch': 0.0}
{'loss': 2.343, 'learning_rate': 5.893657911595132e-07, 'epoch': 0.0}
{'loss': 2.1241, 'learning_rate': 5.957719410634209e-07, 'epoch': 0.0}
{'loss': 1.8846, 'learning_rate': 6.021780909673286e-07, 'epoch': 0.0}
{'loss': 2.0577, 'learning_rate': 6.085842408712364e-07, 'epoch': 0.0}
Traceback (most recent call last):
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1424, in _shutdown_workers
    self._pin_memory_thread.join()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/threading.py", line 1119, in join
    self._wait_for_tstate_lock()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/threading.py", line 1139, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
Traceback (most recent call last):
  File "/home/dang.nh4/PULSE/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation=None)
  File "/home/dang.nh4/PULSE/LLaVA/llava/train/train.py", line 526, in train
    trainer.train()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/accelerate/utils/operations.py", line 581, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/accelerate/utils/operations.py", line 569, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 16, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/peft/peft_model.py", line 1129, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/PULSE/LLaVA/llava/model/language_model/llava_qwen.py", line 104, in forward
    output = super().forward(
             ^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 1173, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 1075, in forward
    hidden_states = self.norm(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 93, in forward
    variance = hidden_states.pow(2).mean(-1, keepdim=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
