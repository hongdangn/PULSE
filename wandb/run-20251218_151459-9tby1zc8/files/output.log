  0%|                                                                                                                           | 0/104061 [00:00<?, ?it/s]/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
                                                                                                                                                           
{'loss': 2.1344, 'learning_rate': 6.406149903907751e-09, 'epoch': 0.0}
{'loss': 1.8546, 'learning_rate': 1.2812299807815502e-08, 'epoch': 0.0}
{'loss': 1.6563, 'learning_rate': 1.9218449711723257e-08, 'epoch': 0.0}
{'loss': 3.3209, 'learning_rate': 2.5624599615631005e-08, 'epoch': 0.0}
{'loss': 2.7208, 'learning_rate': 3.203074951953876e-08, 'epoch': 0.0}
{'loss': 2.4186, 'learning_rate': 3.8436899423446514e-08, 'epoch': 0.0}
{'loss': 2.2969, 'learning_rate': 4.4843049327354265e-08, 'epoch': 0.0}
{'loss': 1.7902, 'learning_rate': 5.124919923126201e-08, 'epoch': 0.0}
{'loss': 1.859, 'learning_rate': 5.7655349135169774e-08, 'epoch': 0.0}
{'loss': 1.9921, 'learning_rate': 6.406149903907752e-08, 'epoch': 0.0}
{'loss': 2.0107, 'learning_rate': 7.046764894298526e-08, 'epoch': 0.0}
{'loss': 2.8202, 'learning_rate': 7.687379884689303e-08, 'epoch': 0.0}
{'loss': 2.029, 'learning_rate': 8.327994875080077e-08, 'epoch': 0.0}
{'loss': 2.1824, 'learning_rate': 8.968609865470853e-08, 'epoch': 0.0}
{'loss': 2.1797, 'learning_rate': 9.609224855861628e-08, 'epoch': 0.0}
{'loss': 2.1202, 'learning_rate': 1.0249839846252402e-07, 'epoch': 0.0}
{'loss': 2.2776, 'learning_rate': 1.0890454836643178e-07, 'epoch': 0.0}
{'loss': 2.3296, 'learning_rate': 1.1531069827033955e-07, 'epoch': 0.0}
{'loss': 3.7835, 'learning_rate': 1.2171684817424729e-07, 'epoch': 0.0}
{'loss': 3.2832, 'learning_rate': 1.2812299807815505e-07, 'epoch': 0.0}
{'loss': 3.1703, 'learning_rate': 1.345291479820628e-07, 'epoch': 0.0}
{'loss': 2.0085, 'learning_rate': 1.4093529788597053e-07, 'epoch': 0.0}
{'loss': 2.0042, 'learning_rate': 1.473414477898783e-07, 'epoch': 0.0}
{'loss': 2.9847, 'learning_rate': 1.5374759769378605e-07, 'epoch': 0.0}
{'loss': 2.0019, 'learning_rate': 1.601537475976938e-07, 'epoch': 0.0}
{'loss': 2.7518, 'learning_rate': 1.6655989750160153e-07, 'epoch': 0.0}
{'loss': 2.2735, 'learning_rate': 1.7296604740550932e-07, 'epoch': 0.0}
{'loss': 1.549, 'learning_rate': 1.7937219730941706e-07, 'epoch': 0.0}
{'loss': 3.2997, 'learning_rate': 1.857783472133248e-07, 'epoch': 0.0}
{'loss': 2.2907, 'learning_rate': 1.9218449711723256e-07, 'epoch': 0.0}
{'loss': 3.3442, 'learning_rate': 1.985906470211403e-07, 'epoch': 0.0}
{'loss': 2.1964, 'learning_rate': 2.0499679692504804e-07, 'epoch': 0.0}
{'loss': 2.1875, 'learning_rate': 2.1140294682895583e-07, 'epoch': 0.0}
{'loss': 1.9062, 'learning_rate': 2.1780909673286357e-07, 'epoch': 0.0}
{'loss': 2.2174, 'learning_rate': 2.242152466367713e-07, 'epoch': 0.0}
{'loss': 3.2709, 'learning_rate': 2.306213965406791e-07, 'epoch': 0.0}
{'loss': 1.8292, 'learning_rate': 2.3702754644458683e-07, 'epoch': 0.0}
{'loss': 2.268, 'learning_rate': 2.4343369634849457e-07, 'epoch': 0.0}
{'loss': 2.1288, 'learning_rate': 2.4983984625240236e-07, 'epoch': 0.0}
{'loss': 2.1462, 'learning_rate': 2.562459961563101e-07, 'epoch': 0.0}
{'loss': 1.9556, 'learning_rate': 2.6265214606021784e-07, 'epoch': 0.0}
{'loss': 2.0361, 'learning_rate': 2.690582959641256e-07, 'epoch': 0.0}
{'loss': 1.6446, 'learning_rate': 2.754644458680333e-07, 'epoch': 0.0}
{'loss': 2.4659, 'learning_rate': 2.8187059577194105e-07, 'epoch': 0.0}
{'loss': 2.2382, 'learning_rate': 2.8827674567584884e-07, 'epoch': 0.0}
{'loss': 2.9043, 'learning_rate': 2.946828955797566e-07, 'epoch': 0.0}
{'loss': 2.0174, 'learning_rate': 3.010890454836643e-07, 'epoch': 0.0}
{'loss': 1.8985, 'learning_rate': 3.074951953875721e-07, 'epoch': 0.0}
{'loss': 2.6715, 'learning_rate': 3.1390134529147985e-07, 'epoch': 0.0}
{'loss': 2.1666, 'learning_rate': 3.203074951953876e-07, 'epoch': 0.0}
{'loss': 2.205, 'learning_rate': 3.267136450992953e-07, 'epoch': 0.0}
{'loss': 3.8582, 'learning_rate': 3.3311979500320306e-07, 'epoch': 0.0}
{'loss': 2.5238, 'learning_rate': 3.395259449071109e-07, 'epoch': 0.0}
{'loss': 1.6067, 'learning_rate': 3.4593209481101864e-07, 'epoch': 0.0}
{'loss': 1.7294, 'learning_rate': 3.523382447149264e-07, 'epoch': 0.0}
{'loss': 2.3694, 'learning_rate': 3.587443946188341e-07, 'epoch': 0.0}
{'loss': 2.2083, 'learning_rate': 3.6515054452274186e-07, 'epoch': 0.0}
{'loss': 1.846, 'learning_rate': 3.715566944266496e-07, 'epoch': 0.0}
{'loss': 2.0706, 'learning_rate': 3.779628443305574e-07, 'epoch': 0.0}
{'loss': 3.2043, 'learning_rate': 3.843689942344651e-07, 'epoch': 0.0}
{'loss': 2.8424, 'learning_rate': 3.9077514413837286e-07, 'epoch': 0.0}
{'loss': 1.7792, 'learning_rate': 3.971812940422806e-07, 'epoch': 0.0}
{'loss': 3.5077, 'learning_rate': 4.0358744394618834e-07, 'epoch': 0.0}
{'loss': 3.3723, 'learning_rate': 4.099935938500961e-07, 'epoch': 0.0}
{'loss': 2.6871, 'learning_rate': 4.163997437540039e-07, 'epoch': 0.0}
{'loss': 2.4017, 'learning_rate': 4.2280589365791166e-07, 'epoch': 0.0}
{'loss': 1.8603, 'learning_rate': 4.292120435618194e-07, 'epoch': 0.0}
{'loss': 2.0671, 'learning_rate': 4.3561819346572713e-07, 'epoch': 0.0}
{'loss': 2.9066, 'learning_rate': 4.4202434336963487e-07, 'epoch': 0.0}
{'loss': 1.7783, 'learning_rate': 4.484304932735426e-07, 'epoch': 0.0}
{'loss': 3.266, 'learning_rate': 4.548366431774504e-07, 'epoch': 0.0}
{'loss': 1.8632, 'learning_rate': 4.612427930813582e-07, 'epoch': 0.0}
{'loss': 2.2873, 'learning_rate': 4.6764894298526593e-07, 'epoch': 0.0}
{'loss': 1.9828, 'learning_rate': 4.7405509288917367e-07, 'epoch': 0.0}
{'loss': 2.0821, 'learning_rate': 4.804612427930814e-07, 'epoch': 0.0}
{'loss': 2.999, 'learning_rate': 4.868673926969891e-07, 'epoch': 0.0}
{'loss': 2.1327, 'learning_rate': 4.932735426008969e-07, 'epoch': 0.0}
{'loss': 1.8035, 'learning_rate': 4.996796925048047e-07, 'epoch': 0.0}
{'loss': 2.1271, 'learning_rate': 5.060858424087125e-07, 'epoch': 0.0}
{'loss': 2.0409, 'learning_rate': 5.124919923126202e-07, 'epoch': 0.0}
{'loss': 2.2488, 'learning_rate': 5.188981422165279e-07, 'epoch': 0.0}
{'loss': 2.2517, 'learning_rate': 5.253042921204357e-07, 'epoch': 0.0}
{'loss': 2.0945, 'learning_rate': 5.317104420243434e-07, 'epoch': 0.0}
{'loss': 1.8639, 'learning_rate': 5.381165919282512e-07, 'epoch': 0.0}
{'loss': 1.8543, 'learning_rate': 5.445227418321589e-07, 'epoch': 0.0}
{'loss': 1.7297, 'learning_rate': 5.509288917360666e-07, 'epoch': 0.0}
{'loss': 2.8562, 'learning_rate': 5.573350416399744e-07, 'epoch': 0.0}
{'loss': 2.2042, 'learning_rate': 5.637411915438821e-07, 'epoch': 0.0}
Traceback (most recent call last):
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1423, in _shutdown_workers
    self._worker_result_queue.put((None, None))
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/multiprocessing/queues.py", line 94, in put
    self._start_thread()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/multiprocessing/queues.py", line 177, in _start_thread
    self._thread.start()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/threading.py", line 964, in start
    _start_new_thread(self._bootstrap, ())
KeyboardInterrupt:
Traceback (most recent call last):
  File "/home/dang.nh4/PULSE/LLaVA/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation=None)
  File "/home/dang.nh4/PULSE/LLaVA/llava/train/train.py", line 519, in train
    trainer.train()
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/accelerate/utils/operations.py", line 581, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/accelerate/utils/operations.py", line 569, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 16, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/peft/peft_model.py", line 1129, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/PULSE/LLaVA/llava/model/language_model/llava_qwen.py", line 104, in forward
    output = super().forward(
             ^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 1173, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 1048, in forward
    layer_outputs = self._gradient_checkpointing_func(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/_compile.py", line 24, in inner
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 230, in forward
    outputs = run_function(*args)
              ^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 773, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 676, in forward
    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 165, in apply_rotary_pos_emb
    cos = cos[position_ids].unsqueeze(unsqueeze_dim)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
