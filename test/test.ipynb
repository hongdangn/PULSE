{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040de2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shortuuid\n",
    "\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import tokenizer_image_token, process_images, get_model_name_from_path\n",
    "from peft import LoraConfig, PeftModel\n",
    "import time\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "\n",
    "def split_list(lst, n):\n",
    "    \"\"\"Split a list into n (roughly) equal-sized chunks\"\"\"\n",
    "    chunk_size = math.ceil(len(lst) / n)  # integer division\n",
    "    return [lst[i:i+chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "\n",
    "\n",
    "def get_chunk(lst, n, k):\n",
    "    chunks = split_list(lst, n)\n",
    "    return chunks[k]\n",
    "\n",
    "def load_module_state(model, module_path):\n",
    "    model_state = model.state_dict()\n",
    "    module_state = torch.load(module_path)\n",
    "    update_state = {k: v for k, v in module_state.items() if k in model_state}\n",
    "\n",
    "    num_loaded_params = sum(p.numel() for n, p in update_state.items())\n",
    "    print(f\"The number of loaded parameters from {module_path}: {num_loaded_params}\")\n",
    "\n",
    "    model_state.update(update_state)\n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "\n",
    "    # Model\n",
    "    # model_path = args.model_path\n",
    "model_path = \"/home/dang.nh4/PULSE/output/fastvlm1.5B/checkpoint-98876\"\n",
    "model_name = \"apple/FastVLM-1.5B\"\n",
    "model_base = None\n",
    "device = torch.device(\"cuda:\" + str(2))\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, \n",
    "                                                                       model_base, \n",
    "                                                                       model_name,\n",
    "                                                                       lora=True, \n",
    "                                                                        device_map=device)\n",
    "\n",
    "print(f'Loading Pre-trained LoRA model from {model_path}')\n",
    "lora_config = LoraConfig.from_pretrained(model_path)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, \n",
    "                                        model_path, \n",
    "                                        config=lora_config,\n",
    "                                        is_trainable=False)\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "projector_path = os.path.join(model_path, \"mm_projector.pth\")\n",
    "\n",
    "if os.path.exists(projector_path):\n",
    "    load_module_state(model, projector_path)\n",
    "model.to(dtype=torch.bfloat16)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbec4ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code15 = os.listdir(\"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/code15_v4\")\n",
    "len(code15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1f53a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([img for img in code15 if '.png' in img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8de387dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb1 = os.listdir(\"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout\")\n",
    "ptb2 = os.listdir(\"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_ori_papersize_layout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90dd3e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2103"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([img for img in ptb1 if '.png' in img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eec4a73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2295"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([img for img in ptb2 if '.png' in img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d234fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12271"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2205 + 2103 + 7963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dede1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2103"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ptb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7070e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code15_v4\t\t      csn_ori_layout_papersize\t       mimic\t ptb-xl\n",
      "csn_aug_all_layout_papersize  csn_part_noise_layout_papersize  mimic_v4\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "342ebf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "image_folder = \"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg\"\n",
    "data_path = \"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ECGInstruct_small.json\"\n",
    "list_data_dict = json.load(open(data_path, \"r\"))\n",
    "\n",
    "new_list_data_dict = []\n",
    "imgs = []\n",
    "for data_dict in list_data_dict:\n",
    "    if 'ptb-xl' in data_dict['image'] or 'code15' in data_dict['image']:\n",
    "        new_list_data_dict.append(data_dict)\n",
    "        imgs.append(os.path.join(image_folder, data_dict['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d52708de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42284"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f78671d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42284"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_list_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "571d64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg\"\n",
    "unk_images = []\n",
    "\n",
    "for image in new_list_data_dict:\n",
    "    if not os.path.exists(os.path.join(image_folder, image['image'])):\n",
    "        unk_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42b4513b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unk_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97f93c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_images[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58399f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_list_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbb7283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecg  ECGInstruct.json  ECGInstruct_small.json  shard_30.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/disk1/backup_user/dang.nh4/ecg_instruct/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e6e9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg\"\n",
    "x = []\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    imgs_path = os.path.join(path, folder)\n",
    "    x.extend(os.listdir(imgs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b88c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24455"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642444b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd LLaVA\n",
    "# python llava/eval/run_llava.py --model-path \"PULSE-ECG/PULSE-7B\" --image-file \"images/ecg_example.png\" --query \"What are the main features in this ECG image?\" --conv-mode \"llava_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1da539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/dang.nh4/PULSE/LLaVA\")\n",
    "\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import (\n",
    "    get_model_name_from_path,\n",
    ")\n",
    "from llava.model import LlavaQwen2ForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e365f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-20 16:31:48,591] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dang.nh4/miniconda3/envs/ecg-qa/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/dang.nh4/PULSE/\")\n",
    "from llava.model import *\n",
    "import torch\n",
    "\n",
    "model = LlavaQwen2ForCausalLM.from_pretrained(\n",
    "    \"apple/FastVLM-1.5B\",\n",
    "    cache_dir=None,\n",
    "    attn_implementation=None,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0295704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlavaQwen2ForCausalLM.from_pretrained(\n",
    "    \"/home/dang.nh4/PULSE/test/dangngu\",\n",
    "    cache_dir=None,\n",
    "    attn_implementation=None,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80836c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./dangngu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13566015",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/dang.nh4/PULSE/test/dangngu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2103\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2069\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[33;03mthis module and its descendants. If :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[32m   2071\u001b[39m \u001b[33;03mthe keys of :attr:`state_dict` must exactly match the keys returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2100\u001b[39m \u001b[33;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[32m   2101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[32m-> \u001b[39m\u001b[32m2103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2105\u001b[39m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m   2106\u001b[39m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] = []\n",
      "\u001b[31mTypeError\u001b[39m: Expected state_dict to be dict-like, got <class 'str'>."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(\"/home/dang.nh4/PULSE/test/dangngu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1ee310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.mm_projector.0.weight\n",
      "model.mm_projector.0.bias\n",
      "model.mm_projector.2.weight\n",
      "model.mm_projector.2.bias\n"
     ]
    }
   ],
   "source": [
    "for n, _ in model.named_parameters():\n",
    "    if \"project\" in n:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad61ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.mm_projector.state_dict(), \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923ae976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.embeddings.class_embedding: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.embeddings.patch_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.embeddings.position_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.pre_layrnorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.pre_layrnorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.post_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.post_layernorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "Loading checkpoint shards: 100%|| 3/3 [00:16<00:00,  5.38s/it]\n",
      "Some weights of the model checkpoint at PULSE-ECG/PULSE-7B were not used when initializing LlavaLlamaForCausalLM: ['model.image_newline']\n",
      "- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_path=\"PULSE-ECG/PULSE-7B\"\n",
    "model_name = get_model_name_from_path(model_path)\n",
    "model = load_pretrained_model(\n",
    "    model_path,\n",
    "    None,\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33752171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df361b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-23 13:00:30--  https://huggingface.co/datasets/PULSE-ECG/ECGInstruct/resolve/main/ECGInstruct.json\n",
      "Resolving huggingface.co (huggingface.co)... 18.67.221.87, 18.67.221.6, 18.67.221.88, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.67.221.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/67168507374ebff4a06b53b6/d8e7dacfbb30b8d12de2cfce81e73c0e0de0d1385f15e1db365a47271eee50d1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251223T060257Z&X-Amz-Expires=3600&X-Amz-Signature=92f28d5edfc4b19e9ed7e22355b303c7631ad47179e44e27825be3c7ebea801d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ECGInstruct.json%3B+filename%3D%22ECGInstruct.json%22%3B&response-content-type=application%2Fjson&x-id=GetObject&Expires=1766473377&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjQ3MzM3N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NzE2ODUwNzM3NGViZmY0YTA2YjUzYjYvZDhlN2RhY2ZiYjMwYjhkMTJkZTJjZmNlODFlNzNjMGUwZGUwZDEzODVmMTVlMWRiMzY1YTQ3MjcxZWVlNTBkMSoifV19&Signature=AO1VxZhhz1pZ9EMK3A-a6qqgsGKkZcy4-O40-r04oTfGV9t2Q58H8RuoDA%7Ew-VuASORN4zclSW5L04VP0iGQzdS1aPWr5XR0IN28EiwnINLf2Rhc81gzUqjsXWI1dog3PhEd8%7Emf%7Et4%7E3btbZbVSvaGR9uBiDl%7EQHmt2FvJWCxaJC9bklykVhs%7EaUznrzBMIDWizc7Kz-RyFFzA3296INuUxqcG-WiJeOkcRf4Wo5B8xlsOiDtAOQb5AncOFlQzV-o%7Eu4RoYs8mrfkDVtdMmlz0YLl1CUVy2L5TPQKTsn6bf9nRZT6%7E9m09JjOPtUzSIwmk5Tcwj-Fjfh0U4MSl8Kg__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
      "--2025-12-23 13:00:36--  https://cas-bridge.xethub.hf.co/xet-bridge-us/67168507374ebff4a06b53b6/d8e7dacfbb30b8d12de2cfce81e73c0e0de0d1385f15e1db365a47271eee50d1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251223T060257Z&X-Amz-Expires=3600&X-Amz-Signature=92f28d5edfc4b19e9ed7e22355b303c7631ad47179e44e27825be3c7ebea801d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ECGInstruct.json%3B+filename%3D%22ECGInstruct.json%22%3B&response-content-type=application%2Fjson&x-id=GetObject&Expires=1766473377&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjQ3MzM3N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NzE2ODUwNzM3NGViZmY0YTA2YjUzYjYvZDhlN2RhY2ZiYjMwYjhkMTJkZTJjZmNlODFlNzNjMGUwZGUwZDEzODVmMTVlMWRiMzY1YTQ3MjcxZWVlNTBkMSoifV19&Signature=AO1VxZhhz1pZ9EMK3A-a6qqgsGKkZcy4-O40-r04oTfGV9t2Q58H8RuoDA%7Ew-VuASORN4zclSW5L04VP0iGQzdS1aPWr5XR0IN28EiwnINLf2Rhc81gzUqjsXWI1dog3PhEd8%7Emf%7Et4%7E3btbZbVSvaGR9uBiDl%7EQHmt2FvJWCxaJC9bklykVhs%7EaUznrzBMIDWizc7Kz-RyFFzA3296INuUxqcG-WiJeOkcRf4Wo5B8xlsOiDtAOQb5AncOFlQzV-o%7Eu4RoYs8mrfkDVtdMmlz0YLl1CUVy2L5TPQKTsn6bf9nRZT6%7E9m09JjOPtUzSIwmk5Tcwj-Fjfh0U4MSl8Kg__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
      "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.67.221.108, 18.67.221.11, 18.67.221.81, ...\n",
      "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.67.221.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c -P /mnt/disk1/backup_user/dang.nh4/ecg_instruct https://huggingface.co/datasets/PULSE-ECG/ECGInstruct/resolve/main/ECGInstruct.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c755e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "t = []\n",
    "\n",
    "for item in data:\n",
    "    # if os.path.exists(os.path.join(imgs_path, item['image'])):\n",
    "        z.append(item)\n",
    "        # t.append(os.path.join(imgs_path, item['image']))\n",
    "        t.append(item['conversations'][0]['value'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "747c27ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156110"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "72f8b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nReview the ECG image and select every applicable option from the given set. List your picks, dividing them with commas.\\nQuestion: Is left ventricular hypertrophy indicated by this ECG?\\nOptions: no, not sure, yes\\n\\nConvey the right answer sans any expounding.'}, {'from': 'gpt', 'value': 'yes'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-5742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nYou are provided with an ECG signal image. Please classify the ECG image into the following diagnostic statement classes:\\nNORM: Normal ECG\\nMI: Myocardial Infarction\\nSTTC: ST/T Change\\nCD: Conduction Disturbance\\nHYP: Hypertrophy. Give the class nomenclature and include a semicolon right after.'}, {'from': 'gpt', 'value': 'HYP; STTC; MI'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'PTB-XL'}\n",
      "{'id': 'ptb-xl-5742-mcq', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nWhat is the significance of the left axis deviation in this ECG image?\\nA. Right ventricular hypertrophy\\nB. Left ventricular hypertrophy\\nC. Borderline left axis deviation\\nD. Right atrial enlargement'}, {'from': 'gpt', 'value': \"The ECG shows a borderline left axis deviation, which means that the overall direction of the heart's electrical activity is slightly shifted to the left. This can be a normal variant or associated with certain cardiac conditions. The left axis deviation may indicate that the left ventricle is dominant in terms of electrical activity, but it is not a definitive indicator of any specific cardiac condition.\\n\\nWe can conclude that the answer is C. Borderline left axis deviation\"}], 'metadata': {'subtask': 'feature', 'type': 'multiple-choice'}, 'source': 'PTB-XL'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nEvaluate the presented ECG image and choose all suitable options from those listed.\\nQuestion: What is the diagnostic symptom that can be identified from this ECG, first degree av block or non-specific ischemic, when we ignore any symptoms that are uncertain?\\nOptions: none, first degree av block, non-specific ischemic\\n\\nOnly answer based on the given Options without any explanation.'}, {'from': 'gpt', 'value': 'non-specific ischemic'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nGiven this ECG image, please answer the following question. From the provided options, select all that apply. List your selections, separated by semicolons.\\nQuestion: Is lead aVL showing indications of inverted t-waves in this ECG?\\nOptions: no, yes\\n\\nProvide the accurate response without additional details.'}, {'from': 'gpt', 'value': 'yes'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-5742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nIdentify the possible causes of the inverted T waves seen in leads I, aVL, V4, V5, and V6. Select one correct answer from the options below.\\n\\nLV strain, Ischaemia, Right atrial enlargement, Left ventricular hypertrophy, Borderline left axis deviation, Combination of LV strain and Ischaemia\\n\\nRespond with the correct answer.'}, {'from': 'gpt', 'value': 'Combination of LV strain and Ischaemia'}], 'metadata': {'subtask': 'morphology', 'type': 'multiple-choice'}, 'source': 'PTB-XL'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': \"<image>\\nYou're assisting in a cardiac clinic. Your task: evaluate the patient's ECG, select all appropriate interpretations from the options, and list them with slashes.\\nQuestion: Can you specify the diagnostic symptoms shown in this ECG, including those that are inconclusive?\\nOptions: ischemic in anteroseptal leads, non-specific ischemic, ischemic in anterolateral leads, complete left bundle branch block, myocardial infarction in inferoposterolateral leads, complete right bundle branch block, left ventricular hypertrophy, myocardial infarction in anteroseptal leads\\n\\nDirect provide the correct answer without explanation.\"}, {'from': 'gpt', 'value': 'myocardial infarction in anteroseptal leads/non-specific ischemic/left ventricular hypertrophy'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nIn light of the ECG image, choose every applicable option from the given choices. Present your selections in a slashes-separated format.\\nQuestion: Can lead II provide evidence of inverted t-waves in this ECG?\\nOptions: no, yes\\n\\nConvey the right answer sans any expounding.'}, {'from': 'gpt', 'value': 'no'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nBased on the ECG image provided, please select all applicable options from the given choices. List your selections, separated by semicolons.\\nQuestion: What are the leads that demonstrate symptoms of inverted t-waves in this ECG?\\nOptions: lead V6, lead I, lead II, lead V2, lead aVL, none, lead V3, lead aVF, lead III, lead V4, lead aVR, lead V1, lead V5\\n\\nSupply the correct answer devoid of any elucidation.'}, {'from': 'gpt', 'value': 'lead I; lead aVL; lead V4; lead V5; lead V6'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nAssess the ECG image and identify all pertinent options from the provided set. Enumerate your selections, using semicolons as delimiters.\\nQuestion: Is lead I showing indications of non-specific st depression in this ECG?\\nOptions: no, yes\\n\\nConvey the right answer sans any expounding.'}, {'from': 'gpt', 'value': 'no'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nAssess the ECG image and identify all pertinent options from the provided set. Enumerate your selections, using slashes as delimiters.\\nQuestion: Is there evidence of hypertrophy on this ECG?\\nOptions: no, not sure, yes\\n\\nDirect provide the correct answer without explanation.'}, {'from': 'gpt', 'value': 'yes'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nIn this ECG reading challenge, your task is to analyze the image, choose all applicable options from the given set, and present your selections separated by slashes.\\nQuestion: Can you tell me which leads in this ECG show features of non-specific st depression symptoms?\\nOptions: lead V6, lead I, lead aVR, lead V2, lead V3, lead III, lead V5, none, lead aVF, lead V4, lead V1, lead II, lead aVL\\n\\nDirect provide the correct answer without explanation.'}, {'from': 'gpt', 'value': 'lead V5/lead V6'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-5742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nYou are provided with an ECG signal image. Please classify the ECG image into the following diagnostic statement classes:\\nNORM: Normal ECG\\nMI: Myocardial Infarction\\nSTTC: ST/T Change\\nCD: Conduction Disturbance\\nHYP: Hypertrophy. Give the class nomenclature and include a semicolon right after.'}, {'from': 'gpt', 'value': 'HYP; STTC; MI'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'PTB-XL'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nAs part of a heart health assessment, your task is to examine the ECG, identify all fitting options from the provided list, and enumerate them using slashes.\\nQuestion: Are there any indications of non-specific st depression in lead V4 on this ECG reading?\\nOptions: no, yes\\n\\nProvide the accurate response without additional details.'}, {'from': 'gpt', 'value': 'no'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nIn light of the ECG image, choose every applicable option from the given choices.\\nQuestion: Is there any evidence of non-specific st depression in lead aVL on this ECG recording?\\nOptions: no, yes\\n\\nConvey the right answer sans any expounding.'}, {'from': 'gpt', 'value': 'no'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nReview the ECG image and select every applicable option from the given set. List your picks, dividing them with commas.\\nQuestion: What is the diagnostic symptom that can be identified from this ECG, left ventricular hypertrophy or myocardial infarction in anteroseptal leads, when we ignore any symptoms that are uncertain?\\nOptions: myocardial infarction in anteroseptal leads, left ventricular hypertrophy, none\\n\\nFurnish the accurate solution without added commentary.'}, {'from': 'gpt', 'value': 'left ventricular hypertrophy, myocardial infarction in anteroseptal leads'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nConsidering the ECG image shown, pick all fitting options from the provided list. Express your selections as a commas-delimited series.\\nQuestion: What are the signs related to the form that this ECG shows in lead aVL?\\nOptions: non-specific t-wave changes, inverted t-waves, non-specific st depression, q waves present, voltage criteria (qrs) for left ventricular hypertrophy, high qrs voltage, non-diagnostic t abnormalities, non-specific st elevation\\n\\nProvide the accurate response without additional details.'}, {'from': 'gpt', 'value': 'inverted t-waves'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nExamining the provided ECG image, choose all relevant options from the list. Present your selections as a slashes-separated list.\\nQuestion: Which form-related abnormalities can be observed in this ECG?\\nOptions: low qrs voltages in the frontal and horizontal leads, atrial premature complex, low amplitude t-wave, non-specific st depression, abnormal qrs, prolonged pr interval, long qt-interval, inverted t-waves\\n\\nState the precise answer without any clarification.'}, {'from': 'gpt', 'value': 'non-specific st depression/inverted t-waves'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-5742-mcq', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nWhat is the significance of the left axis deviation in this ECG image?\\nA. Right ventricular hypertrophy\\nB. Left ventricular hypertrophy\\nC. Borderline left axis deviation\\nD. Right atrial enlargement'}, {'from': 'gpt', 'value': \"The ECG shows a borderline left axis deviation, which means that the overall direction of the heart's electrical activity is slightly shifted to the left. This can be a normal variant or associated with certain cardiac conditions. The left axis deviation may indicate that the left ventricle is dominant in terms of electrical activity, but it is not a definitive indicator of any specific cardiac condition.\\n\\nWe can conclude that the answer is C. Borderline left axis deviation\"}], 'metadata': {'subtask': 'feature', 'type': 'multiple-choice'}, 'source': 'PTB-XL'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nReview the ECG image and select every applicable option from the given set. List your picks, dividing them with slashes.\\nQuestion: Can the presence of inverted t-waves be identified from this ECG?\\nOptions: no, not sure, yes\\n\\nPresent the correct solution with no further explanation.'}, {'from': 'gpt', 'value': 'yes'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nReview the ECG image and select every applicable option from the given set. List your picks, dividing them with semicolons.\\nQuestion: Is there any evidence of inverted t-waves in lead V5 on this ECG recording?\\nOptions: no, yes\\n\\nDirect provide the correct answer without explanation.'}, {'from': 'gpt', 'value': 'yes'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nIn light of the ECG image, choose every applicable option from the given choices. Present your selections in a semicolons-separated format.\\nQuestion: Excluding any uncertain symptoms, what is the diagnostic symptom that this ECG displays, right atrial overload/enlargement or left ventricular hypertrophy?\\nOptions: right atrial overload/enlargement, left ventricular hypertrophy, none\\n\\nSupply the correct answer devoid of any elucidation.'}, {'from': 'gpt', 'value': 'left ventricular hypertrophy'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n",
      "{'id': 'ptb-xl-05742', 'image': 'ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png', 'conversations': [{'from': 'human', 'value': '<image>\\nEvaluate the presented ECG image and choose all suitable options from those listed. Itemize your selections, using slashes to separate them.\\nQuestion: Is there any suggestion of inverted t-waves in lead I on this ECG?\\nOptions: no, yes\\n\\nFurnish the accurate solution without added commentary.'}, {'from': 'gpt', 'value': 'yes'}], 'metadata': {'subtask': 'morphology', 'type': 'close-ended'}, 'source': 'ECG-QA'}\n"
     ]
    }
   ],
   "source": [
    "for item in z:\n",
    "    if \"ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png\" in item['image']:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c83c288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png',\n",
       " '/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in t if i == \"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/ptb-xl/fix_header_aug_all_papersize_layout/05742_hr-0.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "762ab396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "imgs_path = \"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ecg/\"\n",
    "path = \"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ECGInstruct.json\"\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a8440e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = []\n",
    "imgs = []\n",
    "\n",
    "for item in data:\n",
    "    if \"code15\" in item['image'] or 'ptb-xl' in item['image']:\n",
    "        if os.path.exists(os.path.join(imgs_path, item['image'])):\n",
    "            small_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/disk1/backup_user/dang.nh4/ecg_instruct/ECGInstruct_code.json\", 'w') as f:\n",
    "    json.dump(small_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77193f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}\n",
    "\n",
    "for img in imgs:\n",
    "    if img not in x:\n",
    "        x[img] = 0\n",
    "\n",
    "    x[img] += 1\n",
    "\n",
    "for img in x:\n",
    "    if x[img] > 2:\n",
    "        print(img)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18c90fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138748"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2dcd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/cuda/__init__.py:51: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"apple/FastVLM-1.5B\",\n",
    "    cache_dir=None,\n",
    "    model_max_length=512,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45d87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dang.nh4/miniconda3/envs/ecg-qa/lib/python3.11/site-packages/torch/cuda/__init__.py:51: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "projector_path = \"/home/dang.nh4/PULSE/output/fastvlm1.5B/checkpoint-98876/mm_projector.pth\"\n",
    "import torch\n",
    "x = torch.load(projector_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5337a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model.model.model.mm_projector.0.weight': Parameter containing:\n",
       " tensor([[ 0.0081,  0.0055, -0.0216,  ..., -0.0118, -0.0072, -0.0222],\n",
       "         [ 0.0063,  0.0044, -0.0151,  ..., -0.0024,  0.0095,  0.0229],\n",
       "         [ 0.0006,  0.0055, -0.0188,  ..., -0.0020, -0.0090,  0.0315],\n",
       "         ...,\n",
       "         [ 0.0061,  0.0073, -0.0090,  ...,  0.0115, -0.0069,  0.0031],\n",
       "         [ 0.0061, -0.0143,  0.0197,  ..., -0.0095,  0.0095, -0.0126],\n",
       "         [-0.0029, -0.0153,  0.0019,  ..., -0.0449, -0.0031, -0.0148]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " 'base_model.model.model.mm_projector.0.bias': Parameter containing:\n",
       " tensor([-0.0022,  0.0093, -0.0226,  ..., -0.0153,  0.0023,  0.0125],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " 'base_model.model.model.mm_projector.2.weight': Parameter containing:\n",
       " tensor([[-0.0038, -0.0132,  0.0186,  ...,  0.0199, -0.0041,  0.0287],\n",
       "         [-0.0150, -0.0123,  0.0227,  ..., -0.0171,  0.0156, -0.0078],\n",
       "         [ 0.0212,  0.0249,  0.0339,  ...,  0.0042, -0.0322,  0.0349],\n",
       "         ...,\n",
       "         [ 0.0231, -0.0170, -0.0166,  ...,  0.0157,  0.0315,  0.0065],\n",
       "         [ 0.0080,  0.0168,  0.0177,  ..., -0.0172,  0.0126,  0.0498],\n",
       "         [ 0.0311, -0.0342,  0.0151,  ...,  0.0197,  0.0104, -0.0111]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " 'base_model.model.model.mm_projector.2.bias': Parameter containing:\n",
       " tensor([ 0.0102, -0.0242,  0.0223,  ..., -0.0250, -0.0018, -0.0020],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
